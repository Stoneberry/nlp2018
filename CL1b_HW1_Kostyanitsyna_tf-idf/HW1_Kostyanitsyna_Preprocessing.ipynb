{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Анастасия Косятницына \n",
    "\n",
    "#### БКЛ-151"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/Stoneberry/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from pymystem3 import Mystem\n",
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "import re\n",
    "import nltk\n",
    "mystem = Mystem()\n",
    "morph = MorphAnalyzer()\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "pd.set_option('max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('data/sentiment_twitter/train_sentiment_ttk.tsv', sep='\\t')\n",
    "test_data = pd.read_csv('data/sentiment_twitter/test_sentiment_ttk.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.0 Бейзлайн без нормализации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Без предворительной обработки данных посмотрим на accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vecrotizer(train_data, test_data):\n",
    "    count_vectorizer = CountVectorizer()\n",
    "    count_vectorizer.fit(train_data.values) \n",
    "\n",
    "    X_train = count_vectorizer.transform(train_data.values)\n",
    "    X_test = count_vectorizer.transform(test_data.values)\n",
    "    return X_train, X_test, count_vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, count_vectorizer = vecrotizer(train_data.text, test_data.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8208, 20511)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 20511)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_data.label.values\n",
    "y_test = test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перебор параметра C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(X_train, y_train):\n",
    "    log = LogisticRegression(penalty=\"l1\")\n",
    "    params = {'C': [0.01, 0.1, 1, 10, 100]}\n",
    "    clf = GridSearchCV(log, param_grid=params)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = grid(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наилучший результат прогрмма показала при С = 10. Его и будем использовать в дальнейшем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def log(X_train2, y_train, X_test2, y_test):\n",
    "    clf = LogisticRegression(penalty=\"l1\", C=10)\n",
    "    clf.fit(X_train2, y_train)\n",
    "    y_pred2 = clf.predict(X_test2)\n",
    "    normal = accuracy_score(y_test, y_pred2)\n",
    "    return clf, normal, y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, base, y_pred = log(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бейзлайн"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6713729308666018"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.67      0.70       902\n",
      "          0       0.66      0.75      0.71       972\n",
      "          1       0.35      0.26      0.30       180\n",
      "\n",
      "avg / total       0.67      0.67      0.67      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5666229777804013\n",
      "Микросредняя F1 мера -  0.6713729308666018\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_important(vectorizer, clf, topn=10):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    classes = clf.classes_\n",
    "    importances = clf.coef_\n",
    "    for i, cls in enumerate(classes):\n",
    "        print('Значимые слова для класса - ', cls)\n",
    "        important_words = sorted(list(zip(features, importances[i])), key=lambda x: abs(x[1]), reverse=True)[:topn]\n",
    "        print([word for word,_ in important_words])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значимые слова для класса -  -1\n",
      "['собираются', 'сбой', 'evakobb', 'обман', 'отправлялись', 'нему', 'керчи', 'перебоями', 'amaranth815', 'прогресс']\n",
      "\n",
      "Значимые слова для класса -  0\n",
      "['нему', 'собираются', 'хороший', 'жителям', 'прокомментировала', 'jivh4eenpq', 'расторгнуть', 'иа', 'прочность', 'гавно']\n",
      "\n",
      "Значимые слова для класса -  1\n",
      "['здорово', 'фотоед', 'специалистом', 'ожидал', 'радовать', 'обожаю', 't1cw25qbrz', 'расширяется', 'люблю', 'выросла']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_important(count_vectorizer, clf, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Добавить лемматизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для улучшения работы программы уберем пунктуацию, стоп-слова из nltk.corpus и приведем слова к лемме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation, digits\n",
    "\n",
    "punctuation = set(punctuation + '«»—…“”\\n\\t' + digits)\n",
    "punctuation.remove('@')\n",
    "table = str.maketrans({ch: None for ch in punctuation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    \n",
    "    words_normalized_no_stops = []\n",
    "    \n",
    "    good_tokens = [word for word in word_tokenize(text) if len(text) > 1 \n",
    "                                                    and not all([ch in punctuation for ch in word])]\n",
    "    words_normalized = [morph.parse(token)[0].normal_form for token in good_tokens]\n",
    "    for word in words_normalized:\n",
    "        if word not in stops:\n",
    "            words_normalized_no_stops.append(word)\n",
    "    \n",
    "    return ' '.join(words_normalized_no_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized'] = train_data['text'].apply(normalize)\n",
    "test_data['normalized'] = test_data['text'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, count_vectorizer = vecrotizer(train_data.normalized, test_data.normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8208, 14436)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2054, 14436)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, normal, y_pred2 = log(X_train2, y_train, X_test2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6626095423563778"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.75      0.61      0.67       902\n",
      "          0       0.65      0.77      0.71       972\n",
      "          1       0.35      0.32      0.33       180\n",
      "\n",
      "avg / total       0.67      0.66      0.66      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5718232190860312\n",
      "Микросредняя F1 мера -  0.6626095423563778\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred2))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred2, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred2, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат ухудшился. Это может быть связано с тем, что стоп слова, которые используются по умолчанию включают в себя такие слова, которые могут повлиять на определение тональности твита. Например, не, которое в сочетании с глаголом, может кардинально поменять смысл всего сообщения (понравилось vs не понравилось). Попробуем посчитать без удаления стоп-слов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Проанализировать важные признаки, fp, fn, confusion matrix, изменить правила препроцессинга "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize2(text):\n",
    "    \n",
    "    words_normalized_no_stops = []\n",
    "    \n",
    "    good_tokens = [word for word in word_tokenize(text) if len(text) > 1 \n",
    "                                                    and not all([ch in punctuation for ch in word])]\n",
    "    words_normalized = [morph.parse(token)[0].normal_form for token in good_tokens]\n",
    "    \n",
    "    return ' '.join(words_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized_with_stops'] = train_data['text'].apply(normalize2)\n",
    "test_data['normalized_with_stops'] = test_data['text'].apply(normalize2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train3, X_test3, count_vectorizer = vecrotizer(train_data.normalized_with_stops, test_data.normalized_with_stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf, normal_with_stops, y_pred3 = log(X_train3, y_train, X_test3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6801363193768257"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_with_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.67      0.70       902\n",
      "          0       0.68      0.76      0.71       972\n",
      "          1       0.42      0.33      0.37       180\n",
      "\n",
      "avg / total       0.68      0.68      0.68      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5945907742000814\n",
      "Микросредняя F1 мера -  0.6801363193768257\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred3))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred3, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred3, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Важные признаки:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значимые слова для класса -  -1\n",
      "['задолженность', 'amaranth815', 'оштрафовать', 'атаковать', 'сбой', 'турбокнопка', 'уезжать', 'добиться', 'расторгнуть', 'испытывать']\n",
      "\n",
      "Значимые слова для класса -  0\n",
      "['650р', 'топливо', 'расторгнуть', 'гавный', 'испытывать', 'вносить', 'достоверно', 'задолженность', 'слогана', 'инноватор']\n",
      "\n",
      "Значимые слова для класса -  1\n",
      "['lizinastusha', 'здорово', 'адекватный', '6j3mfzcy5u', 'мило', 'топливо', 'расширяться', 'инноватор', 'youdicuudv', 'эфирный']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_important(count_vectorizer, clf, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Достаточно низкий accuracy может быть объяснен тем, что, как видно из списка важных признаков, что некоторые слова являются важными сразу для нескольких классов. Например, испытывать, расторгнуть для -1 и 0; инноватор, топливо для 0 и 1.  Помимо этого, в список значимых признаков для отрицательного класса входят такие отрицательно маркированные слова, как атаковать, сбой, оштрафовать, задолженность, которые вряд могут встретиться в положительных твитах, что помогает хорошо отделить этот класс. Для нейтрального и положительного таких слов практически нет, кроме как здорово и мило у положительного. Это может повлиять на работу программы. Проверим свои догадки с помощью матрицы ошибок. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[602, 269,  31],\n",
       "       [186, 735,  51],\n",
       "       [ 37,  83,  60]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y_test, y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На основе результатов confusion_matrix видно, что у программы действительно возникают трудности в разграничивании нейтрального класса от положительного. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3 Подобрать параметры в классификаторе и векторайзере"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "?TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала посмотрим на неизмененных данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfidfVectorize(train_data, test_data):\n",
    "    tfidf = TfidfVectorizer()\n",
    "    tfidf.fit(train_data.values)\n",
    "    X_train = tfidf.transform(train_data.values)\n",
    "    X_test = tfidf.transform(test_data.values)\n",
    "    return X_train, X_test, tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6635832521908471"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, tfidf = TfidfVectorize(train_data.text, test_data.text)\n",
    "clf, base_tf, y_pred = log(X_train, y_train, X_test, y_test)\n",
    "\n",
    "base_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значимые слова для класса -  -1\n",
      "['сбой', 'перебоями', 'собираются', 'tele2', 'нему', 'заблокировал', 'говно', 'траффику', 'подожгли', 'керчи']\n",
      "\n",
      "Значимые слова для класса -  0\n",
      "['иа', 'собираются', 'нему', 'жителям', 'прокомментировала', 'обратилась', 'вторая', 'вносил', 'просит', 'гавно']\n",
      "\n",
      "Значимые слова для класса -  1\n",
      "['люблю', 'ожидал', 'заработали', 'энергию', 'специалистом', 'текущих', 'выросла', 'обожаю', 'рубежом', 'заработал']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_important(tfidf, clf, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализованные - стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6475170399221032"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train2, X_test2, tfidf = TfidfVectorize(train_data.normalized, test_data.normalized)\n",
    "clf, norm_tf, y_pred2 = log(X_train2, y_train, X_test2, y_test)\n",
    "\n",
    "norm_tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значимые слова для класса -  -1\n",
      "['задолженность', 'оштрафовать', 'tele2', 'сбой', 'позор', 'атаковать', 'говно', 'получаться', 'иа', 'угроза']\n",
      "\n",
      "Значимые слова для класса -  0\n",
      "['восстановление', 'иа', 'гавный', 'поведенческий', 'кончаться', 'топливо', 'позор', '650р', 'ловить', 'прокомментировать']\n",
      "\n",
      "Значимые слова для класса -  1\n",
      "['адекватный', 'понравиться', 'поезд', 'защита', 'частный', '6j3mfzcy5u', 'youdicuudv', 'мощь', 'топливо', 'инноватор']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_important(tfidf, clf, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормализованные + стоп-слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6713729308666018"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train3, X_test3, tfidf = TfidfVectorize(train_data.normalized_with_stops, test_data.normalized_with_stops)\n",
    "clf, norm_stops_tf, y_pred3 = log(X_train3, y_train, X_test3, y_test)\n",
    "\n",
    "norm_stops_tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Значимые слова для класса -  -1\n",
      "['оштрафовать', 'сбой', 'tele2', 'атаковать', 'говно', 'beeline_omsk', 'прекрасно', 'обман', 'уезжать', 'испытывать']\n",
      "\n",
      "Значимые слова для класса -  0\n",
      "['гавный', 'топливо', 'иа', 'восстановление', 'расторгнуть', '650р', 'поведенческий', 'доллар', 'хуй', 'инноватор']\n",
      "\n",
      "Значимые слова для класса -  1\n",
      "['lizinastusha', 'адекватный', 'здорово', 'понравиться', 'мощь', 'защита', 'инноватор', '6j3mfzcy5u', 'частный', 'довольный']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_important(tfidf, clf, topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итог"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CountV</th>\n",
       "      <th>Data</th>\n",
       "      <th>TfidfV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.671373</td>\n",
       "      <td>Без изменений</td>\n",
       "      <td>0.663583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.662610</td>\n",
       "      <td>Нормализация - стоп-слова</td>\n",
       "      <td>0.647517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.680136</td>\n",
       "      <td>Нормализация + стоп-слова</td>\n",
       "      <td>0.671373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     CountV                       Data    TfidfV\n",
       "0  0.671373              Без изменений  0.663583\n",
       "1  0.662610  Нормализация - стоп-слова  0.647517\n",
       "2  0.680136  Нормализация + стоп-слова  0.671373"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'Data': ['Без изменений', 'Нормализация - стоп-слова', 'Нормализация + стоп-слова'],\n",
    "              'CountV': [base, normal, normal_with_stops],\n",
    "              'TfidfV': [base_tf, norm_tf, norm_stops_tf]\n",
    "             })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно из таблицы, Count_vectorizer показал себя лучше на наших данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем отбор признаков:\n",
    "\n",
    "Удалим ненужныe признаки, общие для всех классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unimportant(vectorizer, clf, topn=10):\n",
    "    features = vectorizer.get_feature_names()\n",
    "    classes = clf.classes_\n",
    "    importances = clf.coef_\n",
    "    answer = []\n",
    "    for i, cls in enumerate(classes):\n",
    "        # print('Не значимые слова для класса - ', cls)\n",
    "        important_words = sorted(list(zip(features, importances[i])), key=lambda x: abs(x[1]), reverse=True)[len(importances) - topn:]\n",
    "        answer.append(set(important_words))\n",
    "        #print([word for word,_ in important_words])\n",
    "        #print()\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "unimp = unimportant(count_vectorizer, clf, topn=2500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "un_words = unimp[0] & unimp[1] & unimp[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = []\n",
    "for word in un_words:\n",
    "    stops.append(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1615"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удалим ненужные признаки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['normalized_new_stops'] = train_data['text'].apply(normalize)\n",
    "test_data['normalized_new_stops'] = test_data['text'].apply(normalize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6815968841285297"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train4, X_test4, count_vectorizer = vecrotizer(train_data.normalized_new_stops,\n",
    "                                                 test_data.normalized_new_stops)\n",
    "clf, normalized_new_stops, y_pred4 = log(X_train4, y_train, X_test4, y_test)\n",
    "normalized_new_stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "         -1       0.73      0.67      0.70       902\n",
      "          0       0.68      0.76      0.72       972\n",
      "          1       0.43      0.33      0.37       180\n",
      "\n",
      "avg / total       0.68      0.68      0.68      2054\n",
      "\n",
      "Макросредняя F1 мера -  0.5804887254021792\n",
      "Микросредняя F1 мера -  0.6713729308666018\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred4))\n",
    "print('Макросредняя F1 мера - ',f1_score(y_test, y_pred3, average='macro'))\n",
    "print('Микросредняя F1 мера - ',f1_score(y_test, y_pred3, average='micro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам удалось еще больше увеличить accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.682570593962999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2700"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
